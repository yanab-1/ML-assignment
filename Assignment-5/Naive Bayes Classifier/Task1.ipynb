{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e029fb0",
   "metadata": {},
   "source": [
    "\n",
    "Task 1: Theory Questions Answer in 2–4 sentences:\n",
    "\n",
    "1. What is the core assumption of Naive Bayes?\n",
    "2. Differentiate between GaussianNB, MultinomialNB, and BernoulliNB.\n",
    "3. Why is Naive Bayes considered suitable for high-dimensional data?\n",
    "\n",
    "1. What is the core assumption of Naive Bayes? The core assumption of Naive Bayes is that all features are conditionally independent of each other given the class label. This means the presence (or value) of one feature does not affect the presence (or value) of another, simplifying computation.\n",
    "\n",
    "2. Differentiate between GaussianNB, MultinomialNB, and BernoulliNB.\n",
    "\n",
    "-->GaussianNB assumes that features follow a normal (Gaussian) distribution and is suitable for continuous data.\n",
    "\n",
    "-->MultinomialNB is used for discrete count data (e.g., word counts in text classification).\n",
    "\n",
    "-->BernoulliNB is ideal for binary/boolean features, where each feature is either 0 or 1 (e.g., word presence/absence).\n",
    "\n",
    "3. Why is Naive Bayes considered suitable for high-dimensional data? Naive Bayes is efficient in high-dimensional spaces because it doesn’t require feature selection or complex computations; its independence assumption allows it to scale linearly with the number of features and perform well even with thousands of dimensions, as often seen in text classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
